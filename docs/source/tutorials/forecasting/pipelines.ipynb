{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e698c5bc",
   "metadata": {},
   "source": [
    "# Pipelines in Time Series Forecasting\n",
    "\n",
    "This tutorial demonstrates how to build robust forecasting pipelines in sktime to avoid data leakage and ensure reproducibility.\n",
    "\n",
    "**Duration:** ~10 minutes\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "- Understand the motivation for using pipelines\n",
    "- Build pipelines with target transformations\n",
    "- Create pipelines with exogenous variable transformations\n",
    "- Compose complex pipelines with multiple transformation types\n",
    "- Use `get_params` and `set_params` for pipeline inspection and tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa19add7",
   "metadata": {},
   "source": [
    "## 1. Motivation for Pipelines\n",
    "\n",
    "Pipelines are essential for:\n",
    "- **Avoiding Data Leakage**: Transformations are fit only on training data\n",
    "- **Reproducibility**: Consistent preprocessing across different datasets\n",
    "- **Maintainability**: Clear separation of preprocessing and modeling steps\n",
    "- **Parameter Tuning**: Unified interface for optimizing all components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sktime.datasets import load_airline, load_longley\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "# Load datasets\n",
    "y = load_airline()\n",
    "y_longley, X_longley = load_longley(return_X_y=True)\n",
    "\n",
    "print(\"Datasets loaded:\")\n",
    "print(f\"Airline: {y.shape} (univariate)\")\n",
    "print(f\"Longley: y={y_longley.shape}, X={X_longley.shape} (with exogenous variables)\")\n",
    "\n",
    "# Split airline data\n",
    "y_train = y.iloc[:-12]\n",
    "y_test = y.iloc[-12:]\n",
    "\n",
    "# Split Longley data\n",
    "split_point = -4\n",
    "y_longley_train, y_longley_test = (\n",
    "    y_longley.iloc[:split_point],\n",
    "    y_longley.iloc[split_point:],\n",
    ")\n",
    "X_longley_train, X_longley_test = (\n",
    "    X_longley.iloc[:split_point],\n",
    "    X_longley.iloc[split_point:],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4770cc",
   "metadata": {},
   "source": [
    "## 2. Target Transformations with Pipelines\n",
    "\n",
    "Let's start with pipelines that transform the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.transformations.compose import TransformerPipeline\n",
    "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "\n",
    "# Create a target transformation pipeline\n",
    "target_transformer = TransformerPipeline(\n",
    "    [(\"boxcox\", BoxCoxTransformer(method=\"mle\")), (\"detrend\", Detrender())]\n",
    ")\n",
    "\n",
    "# Create forecaster with transformed target\n",
    "forecaster_with_target_transform = TransformedTargetForecaster(\n",
    "    [\n",
    "        (\"transform\", target_transformer),\n",
    "        (\"forecaster\", NaiveForecaster(strategy=\"seasonal_last\", sp=12)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Pipeline created: {forecaster_with_target_transform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b2405",
   "metadata": {},
   "source": [
    "### 2.1 Fit and Predict with Target Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a080f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline\n",
    "forecaster_with_target_transform.fit(y_train)\n",
    "\n",
    "# Make predictions (transformations are automatically inverted)\n",
    "y_pred_transformed = forecaster_with_target_transform.predict(fh=range(1, 13))\n",
    "\n",
    "# Compare with simple forecaster\n",
    "forecaster_simple = NaiveForecaster(strategy=\"seasonal_last\", sp=12)\n",
    "forecaster_simple.fit(y_train)\n",
    "y_pred_simple = forecaster_simple.predict(fh=range(1, 13))\n",
    "\n",
    "# Calculate performance\n",
    "mape_simple = mean_absolute_percentage_error(y_test, y_pred_simple)\n",
    "mape_transformed = mean_absolute_percentage_error(y_test, y_pred_transformed)\n",
    "\n",
    "print(f\"MAPE - Simple: {mape_simple:.2%}\")\n",
    "print(f\"MAPE - With Target Transform: {mape_transformed:.2%}\")\n",
    "print(f\"Improvement: {((mape_simple - mape_transformed) / mape_simple * 100):.1f}%\")\n",
    "\n",
    "# Plot results\n",
    "plot_series(\n",
    "    y_train.iloc[-24:],\n",
    "    y_test,\n",
    "    y_pred_simple,\n",
    "    y_pred_transformed,\n",
    "    labels=[\"Training\", \"Actual\", \"Simple\", \"Target Transformed\"],\n",
    "    title=\"Target Transformation Pipeline\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06475142",
   "metadata": {},
   "source": [
    "## 3. Exogenous Variable Transformations\n",
    "\n",
    "Now let's create pipelines that transform exogenous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.compose import ForecastingPipeline\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "\n",
    "# Create exogenous variable transformation pipeline\n",
    "X_transformer = TabularToSeriesAdaptor(\n",
    "    transformer=StandardScaler()  # Standardize exogenous variables\n",
    ")\n",
    "\n",
    "# Create forecasting pipeline with X transformation\n",
    "forecaster_with_X_transform = ForecastingPipeline(\n",
    "    [(\"X_transform\", X_transformer), (\"forecaster\", AutoARIMA(suppress_warnings=True))]\n",
    ")\n",
    "\n",
    "print(f\"Pipeline with X transformation: {forecaster_with_X_transform}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0705341",
   "metadata": {},
   "source": [
    "### 3.1 Fit and Predict with Exogenous Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit pipeline with exogenous variables\n",
    "forecaster_with_X_transform.fit(y_longley_train, X=X_longley_train)\n",
    "\n",
    "# Make predictions\n",
    "fh_longley = range(1, len(y_longley_test) + 1)\n",
    "y_pred_X_transformed = forecaster_with_X_transform.predict(\n",
    "    fh=fh_longley, X=X_longley_test\n",
    ")\n",
    "\n",
    "# Compare with non-transformed\n",
    "forecaster_no_transform = AutoARIMA(suppress_warnings=True)\n",
    "forecaster_no_transform.fit(y_longley_train, X=X_longley_train)\n",
    "y_pred_no_transform = forecaster_no_transform.predict(fh=fh_longley, X=X_longley_test)\n",
    "\n",
    "# Calculate performance\n",
    "mape_no_transform = mean_absolute_percentage_error(y_longley_test, y_pred_no_transform)\n",
    "mape_X_transformed = mean_absolute_percentage_error(\n",
    "    y_longley_test, y_pred_X_transformed\n",
    ")\n",
    "\n",
    "print(f\"MAPE - No X Transform: {mape_no_transform:.2%}\")\n",
    "print(f\"MAPE - X Transformed: {mape_X_transformed:.2%}\")\n",
    "print(\n",
    "    f\"Improvement: {((mape_no_transform - mape_X_transformed) / mape_no_transform * 100):.1f}%\"\n",
    ")\n",
    "\n",
    "# Plot results\n",
    "plot_series(\n",
    "    y_longley_train.iloc[-8:],\n",
    "    y_longley_test,\n",
    "    y_pred_no_transform,\n",
    "    y_pred_X_transformed,\n",
    "    labels=[\"Training\", \"Actual\", \"No Transform\", \"X Transformed\"],\n",
    "    title=\"Exogenous Variable Transformation Pipeline\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6938f3",
   "metadata": {},
   "source": [
    "## 4. Complex Composition: Both Target and Exogenous Transformations\n",
    "\n",
    "Let's create a pipeline that transforms both the target and exogenous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sktime.transformations.series.difference import Differencer\n",
    "\n",
    "# Create comprehensive transformation pipeline\n",
    "\n",
    "# 1. Target transformations\n",
    "y_transformer = TransformerPipeline(\n",
    "    [(\"boxcox\", BoxCoxTransformer(method=\"mle\")), (\"diff\", Differencer(lags=1))]\n",
    ")\n",
    "\n",
    "# 2. Exogenous transformations with dimensionality reduction\n",
    "X_transformer_advanced = TabularToSeriesAdaptor(\n",
    "    transformer=PCA(n_components=2)  # Reduce to 2 components\n",
    ")\n",
    "\n",
    "# 3. Base forecasting pipeline with X transformation\n",
    "base_pipeline = ForecastingPipeline(\n",
    "    [\n",
    "        (\"X_transform\", X_transformer_advanced),\n",
    "        (\"forecaster\", AutoARIMA(suppress_warnings=True)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Complete pipeline with both transformations\n",
    "complete_pipeline = TransformedTargetForecaster(\n",
    "    [(\"y_transform\", y_transformer), (\"pipeline\", base_pipeline)]\n",
    ")\n",
    "\n",
    "print(f\"Complete pipeline: {complete_pipeline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e79b56",
   "metadata": {},
   "source": [
    "### 4.1 Fit and Evaluate Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738730f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit complete pipeline\n",
    "complete_pipeline.fit(y_longley_train, X=X_longley_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_complete = complete_pipeline.predict(fh=fh_longley, X=X_longley_test)\n",
    "\n",
    "# Calculate performance\n",
    "mape_complete = mean_absolute_percentage_error(y_longley_test, y_pred_complete)\n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "print(f\"No Transform:      {mape_no_transform:.2%}\")\n",
    "print(f\"X Transform Only:  {mape_X_transformed:.2%}\")\n",
    "print(f\"Complete Pipeline: {mape_complete:.2%}\")\n",
    "\n",
    "# Plot all results\n",
    "plot_series(\n",
    "    y_longley_train.iloc[-8:],\n",
    "    y_longley_test,\n",
    "    y_pred_no_transform,\n",
    "    y_pred_X_transformed,\n",
    "    y_pred_complete,\n",
    "    labels=[\"Training\", \"Actual\", \"No Transform\", \"X Transform\", \"Complete Pipeline\"],\n",
    "    title=\"Pipeline Comparison\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace008a5",
   "metadata": {},
   "source": [
    "## 5. Pipeline Inspection with get_params and set_params\n",
    "\n",
    "Pipelines provide a unified interface for parameter inspection and modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2c4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect pipeline parameters\n",
    "params = complete_pipeline.get_params()\n",
    "\n",
    "print(\"Pipeline Parameters (first 10):\")\n",
    "for i, (key, value) in enumerate(list(params.items())[:10]):\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nTotal parameters: {len(params)}\")\n",
    "\n",
    "# Show parameter structure\n",
    "print(\"\\nParameter Structure (key patterns):\")\n",
    "key_patterns = set([key.split(\"__\")[0] for key in params.keys()])\n",
    "for pattern in sorted(key_patterns):\n",
    "    matching_keys = [k for k in params.keys() if k.startswith(pattern)]\n",
    "    print(f\"{pattern}: {len(matching_keys)} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed72294",
   "metadata": {},
   "source": [
    "### 5.1 Modifying Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find specific parameters we can modify\n",
    "print(\"Modifiable Parameters Examples:\")\n",
    "\n",
    "# Look for specific parameter types\n",
    "diff_params = [k for k in params.keys() if \"diff\" in k.lower()]\n",
    "pca_params = [k for k in params.keys() if \"pca\" in k.lower()]\n",
    "arima_params = [k for k in params.keys() if \"autoarima\" in k.lower()]\n",
    "\n",
    "print(f\"\\nDifferencing parameters: {diff_params[:3]}...\")  # Show first 3\n",
    "print(f\"PCA parameters: {pca_params[:3]}...\")  # Show first 3\n",
    "print(f\"ARIMA parameters: {arima_params[:3]}...\")  # Show first 3\n",
    "\n",
    "# Modify some parameters\n",
    "new_params = {\n",
    "    \"steps__pipeline__steps__X_transform__transformer__n_components\": 3,  # Change PCA components\n",
    "}\n",
    "\n",
    "# Create new pipeline with modified parameters\n",
    "modified_pipeline = complete_pipeline.set_params(**new_params)\n",
    "\n",
    "print(\"\\nModified PCA components to 3\")\n",
    "print(\n",
    "    f\"New parameter value: {modified_pipeline.get_params()['steps__pipeline__steps__X_transform__transformer__n_components']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e273a1",
   "metadata": {},
   "source": [
    "### 5.2 Parameter Naming Convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed17fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate parameter naming convention\n",
    "print(\"Parameter Naming Convention in sktime Pipelines:\")\n",
    "print(\"\\nFormat: steps__<step_name>__<parameter_name>\")\n",
    "print(\"For nested pipelines: steps__<step1>__steps__<step2>__<parameter>\")\n",
    "\n",
    "# Show examples from our pipeline\n",
    "example_params = [\n",
    "    \"steps__y_transform__steps__boxcox__method\",\n",
    "    \"steps__y_transform__steps__diff__lags\",\n",
    "    \"steps__pipeline__steps__X_transform__transformer__n_components\",\n",
    "    \"steps__pipeline__steps__forecaster__suppress_warnings\",\n",
    "]\n",
    "\n",
    "print(\"\\nExamples from our pipeline:\")\n",
    "for param in example_params:\n",
    "    if param in params:\n",
    "        print(f\"{param}: {params[param]}\")\n",
    "    else:\n",
    "        # Try to find similar parameter\n",
    "        similar = [k for k in params.keys() if param.split(\"__\")[-1] in k]\n",
    "        if similar:\n",
    "            print(f\"{param}: Not found, similar: {similar[0]}\")\n",
    "        else:\n",
    "            print(f\"{param}: Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717898d",
   "metadata": {},
   "source": [
    "## 6. Advanced Pipeline Patterns\n",
    "\n",
    "Let's explore some advanced pipeline construction patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9205a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Conditional transformations\n",
    "from sktime.transformations.series.outlier_detection import HampelFilter\n",
    "\n",
    "# Create a robust pipeline with outlier detection\n",
    "robust_pipeline = TransformedTargetForecaster(\n",
    "    [\n",
    "        (\"outlier_detection\", HampelFilter(window_length=5)),\n",
    "        (\"boxcox\", BoxCoxTransformer()),\n",
    "        (\"forecaster\", NaiveForecaster(strategy=\"seasonal_last\", sp=12)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Robust pipeline: {robust_pipeline}\")\n",
    "\n",
    "# Pattern 2: Feature selection pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "feature_selection_pipeline = ForecastingPipeline(\n",
    "    [\n",
    "        (\"scale\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "        (\"select\", TabularToSeriesAdaptor(SelectKBest(f_regression, k=2))),\n",
    "        (\"forecaster\", AutoARIMA(suppress_warnings=True)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Feature selection pipeline: {feature_selection_pipeline}\")\n",
    "\n",
    "\n",
    "# Pattern 3: Ensemble-ready pipeline\n",
    "def create_forecasting_pipeline(transformer_config, forecaster_config):\n",
    "    \"\"\"Factory function for creating standardized pipelines\"\"\"\n",
    "    transformers = []\n",
    "\n",
    "    if transformer_config.get(\"boxcox\", False):\n",
    "        transformers.append((\"boxcox\", BoxCoxTransformer()))\n",
    "\n",
    "    if transformer_config.get(\"detrend\", False):\n",
    "        transformers.append((\"detrend\", Detrender()))\n",
    "\n",
    "    if transformer_config.get(\"diff_lags\"):\n",
    "        transformers.append((\"diff\", Differencer(lags=transformer_config[\"diff_lags\"])))\n",
    "\n",
    "    if transformers:\n",
    "        target_transform = TransformerPipeline(transformers)\n",
    "        return TransformedTargetForecaster(\n",
    "            [\n",
    "                (\"transform\", target_transform),\n",
    "                (\"forecaster\", forecaster_config[\"forecaster\"]),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        return forecaster_config[\"forecaster\"]\n",
    "\n",
    "\n",
    "# Create different pipeline configurations\n",
    "configs = [\n",
    "    {\n",
    "        \"name\": \"Simple\",\n",
    "        \"transformer\": {\"boxcox\": False, \"detrend\": False},\n",
    "        \"forecaster\": {\"forecaster\": NaiveForecaster(strategy=\"seasonal_last\", sp=12)},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"BoxCox\",\n",
    "        \"transformer\": {\"boxcox\": True, \"detrend\": False},\n",
    "        \"forecaster\": {\"forecaster\": NaiveForecaster(strategy=\"seasonal_last\", sp=12)},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Full\",\n",
    "        \"transformer\": {\"boxcox\": True, \"detrend\": True, \"diff_lags\": 1},\n",
    "        \"forecaster\": {\"forecaster\": NaiveForecaster(strategy=\"seasonal_last\", sp=12)},\n",
    "    },\n",
    "]\n",
    "\n",
    "pipelines = {}\n",
    "for config in configs:\n",
    "    pipelines[config[\"name\"]] = create_forecasting_pipeline(\n",
    "        config[\"transformer\"], config[\"forecaster\"]\n",
    "    )\n",
    "\n",
    "print(\"\\nCreated pipeline variants:\")\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"{name}: {type(pipeline).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dfb452",
   "metadata": {},
   "source": [
    "## 7. Pipeline Best Practices\n",
    "\n",
    "Here are key best practices for building effective pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline Best Practices:\")\n",
    "\n",
    "print(\"\\n1. DATA LEAKAGE PREVENTION:\")\n",
    "print(\"   ✓ Always fit transformers on training data only\")\n",
    "print(\"   ✓ Use pipelines to ensure consistent train/test preprocessing\")\n",
    "print(\"   ✓ Never use future information in transformations\")\n",
    "\n",
    "print(\"\\n2. TRANSFORMATION ORDER:\")\n",
    "print(\"   ✓ Outlier detection → Variance stabilization → Detrending → Differencing\")\n",
    "print(\"   ✓ Feature engineering before dimensionality reduction\")\n",
    "print(\"   ✓ Scaling after feature creation\")\n",
    "\n",
    "print(\"\\n3. PARAMETER MANAGEMENT:\")\n",
    "print(\"   ✓ Use get_params() for inspection\")\n",
    "print(\"   ✓ Use set_params() for tuning\")\n",
    "print(\"   ✓ Follow naming convention: steps__<step>__<param>\")\n",
    "\n",
    "print(\"\\n4. ROBUSTNESS:\")\n",
    "print(\"   ✓ Handle missing values appropriately\")\n",
    "print(\"   ✓ Consider outlier detection for noisy data\")\n",
    "print(\"   ✓ Test pipelines on different data splits\")\n",
    "\n",
    "print(\"\\n5. MAINTAINABILITY:\")\n",
    "print(\"   ✓ Use descriptive step names\")\n",
    "print(\"   ✓ Create reusable pipeline factories\")\n",
    "print(\"   ✓ Document transformation rationale\")\n",
    "\n",
    "# Demonstrate validation\n",
    "print(\"\\n6. VALIDATION EXAMPLE:\")\n",
    "\n",
    "# Test pipeline on different splits\n",
    "validation_results = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    try:\n",
    "        # Fit on training data\n",
    "        pipeline.fit(y_train)\n",
    "        # Predict on test data\n",
    "        pred = pipeline.predict(fh=range(1, 13))\n",
    "        # Calculate error\n",
    "        mape = mean_absolute_percentage_error(y_test, pred)\n",
    "        validation_results[name] = mape\n",
    "        print(f\"   {name}: MAPE = {mape:.2%}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   {name}: Error - {str(e)[:50]}...\")\n",
    "\n",
    "if validation_results:\n",
    "    best_pipeline = min(validation_results.items(), key=lambda x: x[1])\n",
    "    print(f\"\\n   Best pipeline: {best_pipeline[0]} (MAPE: {best_pipeline[1]:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22210e60",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Pipeline Motivation**: Why pipelines are essential for robust forecasting\n",
    "2. **Target Transformations**: Using `TransformedTargetForecaster` for y transformations\n",
    "3. **Exogenous Transformations**: Using `ForecastingPipeline` for X transformations\n",
    "4. **Complex Composition**: Combining both target and exogenous transformations\n",
    "5. **Parameter Management**: Using `get_params` and `set_params` for inspection and tuning\n",
    "6. **Advanced Patterns**: Factory functions and configuration-driven pipelines\n",
    "7. **Best Practices**: Guidelines for building robust and maintainable pipelines\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Data Leakage Prevention**: Pipelines ensure transformations are fit on training data only\n",
    "- **Reproducibility**: Consistent preprocessing across different datasets and experiments\n",
    "- **Unified Interface**: Single point for parameter tuning and model management\n",
    "- **Composability**: Easy to combine different transformation and forecasting components\n",
    "- **Maintainability**: Clear separation of concerns and reusable patterns\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Learn \"Cross-validation and Metrics\" for robust pipeline evaluation\n",
    "- Explore \"Hyperparameter Tuning\" to optimize pipeline parameters\n",
    "- Try \"Probabilistic Forecasting\" to extend pipelines with uncertainty quantification"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
